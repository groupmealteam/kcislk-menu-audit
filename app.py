import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="æ—å£åº·æ©‹åœ‹éš›å­¸æ ¡èœå–®å¯©æ ¸", layout="wide")

# --- æ ¹æ“šã€Šæ ¡å…§èœå–®å¯©é–±åŸå‰‡ã€‹è¨­å®šä¹‹è¦ç¯„ ---
CONTRACT_DATA = {
    "æ–°åŒ—é£Ÿå“": {
        "specs": {"ç¾æ’ˆå°å·": r"80|100", "ç„¡åˆºç™½å¸¶é­š": r"120|150", "æ‰‹ä½œç…å­é ­": r"60", "æ‰‹ä½œæ¼¢å ¡æ’": r"150", "æ‰‹ä½œçƒ¤è‚‰ä¸²": r"80"},
        "spicy_days": ["é€±ä¸€", "é€±äºŒ", "é€±å››"],
        "fried_limit": 1
    },
    "æš–ç¦¾è¼•é£Ÿ": {
        "spicy_days": ["é€±ä¸€", "é€±äºŒ", "é€±å››"],
        "fried_limit": 1
    }
}

# ğŸ’¡ è±å…åå–® (è”¬èœæ°´æœä¸è¨ˆå…¥é£Ÿæé‡è¤‡)
EXEMPT_KEYWORDS = ["å­£ç¯€æ°´æœ", "Fruit", "æ™‚ä»¤è”¬èœ", "Seasonal Vegetable", "å±¥æ­·è”¬èœ", "Fresh Vegetable", "æœ‰æ©Ÿè”¬èœ", "Organic Vegetable"]

def clean_text(text):
    if pd.isna(text): return ""
    return str(text).replace("\n", " ").strip()

def run_audit(df, rule, vendor):
    df = df.fillna("") 
    final_report = []
    
    # 1. å®šä½æ—¥æœŸåˆ—èˆ‡æ˜ŸæœŸåˆ— (ç²¾ç¢ºå°æ‡‰ 2/3, 3/31 ç­‰ä¸åŒæ—¥æœŸ)
    date_row_idx = None
    day_row_idx = None
    for i, row in df.iterrows():
        row_str = "".join([str(c) for c in row])
        if date_row_idx is None and re.search(r"\d{1,2}/\d{1,2}|\d{4}-\d{2}", row_str):
            date_row_idx = i
        if day_row_idx is None and any(d in row_str for d in ["é€±ä¸€", "é€±äºŒ", "é€±ä¸‰", "é€±å››", "é€±äº”"]):
            day_row_idx = i

    if date_row_idx is None or day_row_idx is None:
        return None

    # 2. é€æ¬„(Column)æƒæ
    for col in range(len(df.columns)):
        date_raw = clean_text(df.iloc[date_row_idx, col])
        day_raw = clean_text(df.iloc[day_row_idx, col])
        
        date_match = re.search(r"(\d{1,2}/\d{1,2})|(\d{4}-\d{2}-\d{2})", date_raw)
        weekday_match = re.search(r"é€±[ä¸€äºŒä¸‰å››äº”]", day_raw)
        
        if date_match and weekday_match:
            date_label = date_match.group()
            weekday = weekday_match.group()
            
            raw_dishes = []
            for i in range(len(df)):
                if i in [date_row_idx, day_row_idx]: continue
                cell_val = clean_text(df.iloc[i, col])
                # éæ¿¾éèœåçš„å¹²æ“¾è³‡è¨Š
                if cell_val and not any(k in cell_val for k in ["å¥—é¤", "ç†±é‡", "ä»½", "é›œç³§"]):
                    raw_dishes.append(cell_val)
            
            # --- åˆ¤è®€ A: æ¹¯å“ä¸€è‡´æ€§ (åƒ…ä¸åŒæ™‚å ±éŒ¯) ---
            if vendor == "æš–ç¦¾è¼•é£Ÿ":
                soups = list(set([d for d in raw_dishes if "æ¹¯" in d or "ç¾¹" in d]))
                if len(soups) > 1:
                    final_report.append({
                        "æ—¥æœŸ": date_label, "é€±å¹¾": weekday, "ç•°å¸¸é …ç›®": "æ¹¯å“æ¯”å°", 
                        "åˆ¤è®€çµæœ": f"âŒ æ¹¯å“ä¸åŒï¼šåŒæ™‚å‡ºç¾ã€Œ{soups[0]}ã€èˆ‡ã€Œ{soups[1]}ã€ï¼Œè«‹çµ±ä¸€"
                    })

            # --- åˆ¤è®€ B: é£Ÿæé‡è¤‡æ€§ (ä¸€äº‹ä¸€åˆ—) ---
            seen_ingredients = {} 
            for dish in raw_dishes:
                if any(k in dish for k in EXEMPT_KEYWORDS) or "æ¹¯" in dish or "ç¾¹" in dish:
                    continue
                # æŠ“å–å‰å…©å€‹å­—åšä¸»æ–™è­˜åˆ¥
                core = re.sub(r"[â—ğŸŒ¶ï¸â—â–³() \d gGå…‹/]", "", dish)[:2]
                if len(core) >= 2:
                    if core in seen_ingredients:
                        final_report.append({
                            "æ—¥æœŸ": date_label, "é€±å¹¾": weekday, "ç•°å¸¸é …ç›®": "é£Ÿæé‡è¤‡æ€§", 
                            "åˆ¤è®€çµæœ": f"âŒ ã€Œ{dish}ã€èˆ‡ã€Œ{seen_ingredients[core]}ã€ä¸»æ–™é‡è¤‡ä½¿ç”¨"
                        })
                    seen_ingredients[core] = dish

                # --- åˆ¤è®€ C: ç¦è¾£ & ç¬¦è™Ÿæ¨™ç¤ºè¦ç¯„ ---
                # æ ¹æ“šå¯©é–±åŸå‰‡ï¼šğŸŒ¶ï¸ æˆ– â— (å«è¾£) åœ¨é€±ä¸€äºŒå››ç¦ä¾›
                if weekday in rule["spicy_days"] and ("ğŸŒ¶ï¸" in dish or "â—" in dish):
                    final_report.append({
                        "æ—¥æœŸ": date_label, "é€±å¹¾": weekday, "ç•°å¸¸é …ç›®": dish, 
                        "åˆ¤è®€çµæœ": "ğŸš« ç¦è¾£æ—¥é•è¦ï¼šé€±ä¸€äºŒå››ä¸å¾—ä¾›æ‡‰å«è¾£æˆ–æ¨™è¨˜ â— ä¹‹é¤é»"
                    })
                
                # æ–°åŒ—é£Ÿå“å…‹é‡æ ¡å°
                if vendor == "æ–°åŒ—é£Ÿå“":
                    for s_name, s_reg in rule.get("specs", {}).items():
                        if s_name in dish and not re.search(s_reg, dish):
                            final_report.append({
                                "æ—¥æœŸ": date_label, "é€±å¹¾": weekday, "ç•°å¸¸é …ç›®": dish, 
                                "åˆ¤è®€çµæœ": f"âš ï¸ è¦æ ¼ç¼ºå¤±ï¼šé ˆä¾å”è­°æ¨™è¨» {s_reg}g"
                            })

            # --- åˆ¤è®€ D: æ²¹ç‚¸çµ±è¨ˆ ---
            total_fried = "".join(raw_dishes).count("â—")
            if total_fried > rule["fried_limit"]:
                final_report.append({
                    "æ—¥æœŸ": date_label, "é€±å¹¾": weekday, "ç•°å¸¸é …ç›®": "æ²¹ç‚¸çµ±è¨ˆ", 
                    "åˆ¤è®€çµæœ": f"ğŸŸ æ²¹ç‚¸è¶…æ¨™ï¼šç•¶å¤©å‡ºç¾ {total_fried} æ¬¡æ²¹ç‚¸æ¨™è¨˜ (â—)"
                })

    return final_report

# --- Streamlit ä½¿ç”¨ä»‹é¢ ---
st.title("ğŸ›¡ï¸ æ—å£åº·æ©‹åœ‹éš›å­¸æ ¡èœå–®å¯©æ ¸")
st.markdown("å·²æ•´åˆã€Šæ ¡å…§èœå–®å¯©é–±åŸå‰‡ã€‹ï¼šåŒ…å«æ¨™ç¤ºç¬¦è™Ÿæª¢æŸ¥ã€é£Ÿæé‡è¤‡æ’é™¤ã€æ¹¯å“ä¸€è‡´æ€§åµæ¸¬ã€‚")

up = st.file_uploader("ğŸ‘‰ è«‹ä¸Šå‚³ Excel èœå–®æª”æ¡ˆ (xlsx)", type=["xlsx"])

if up:
    is_light_file = "è¼•é£Ÿ" in up.name
    excel = pd.read_excel(up, sheet_name=None, header=None)
    for sheet_name, df in excel.items():
        vendor = "æš–ç¦¾è¼•é£Ÿ" if (is_light_file or "è¼•é£Ÿ" in sheet_name) else "æ–°åŒ—é£Ÿå“"
        st.subheader(f"ğŸ“Š å¯©æ ¸å°è±¡ï¼š{sheet_name} (å» å•†è¦å‰‡ï¼š{vendor})")
        
        results = run_audit(df, CONTRACT_DATA[vendor], vendor)
        
        if results:
            st.error(f"ğŸš© ç™¼ç¾é•è¦é …ç›® (å·²æŒ‰æ—¥æœŸæ‹†åˆ†ï¼Œè«‹å» å•†é€åˆ—ä¿®æ­£)ï¼š")
            st.table(pd.DataFrame(results))
        else:
            st.success("ğŸ‰ æœ¬é ç¶“æ·±åº¦ç¨½æ ¸ï¼Œå®Œå…¨ç¬¦åˆå¯©é–±åŸå‰‡ï¼")
        st.divider()
